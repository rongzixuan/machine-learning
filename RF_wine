from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd

url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'
df = pd.read_csv(url, header = None)
df.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash', 
              'Alcalinity of ash', 'Magnesium', 'Total phenols', 
              'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 
              'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline']
print(df.info())
print(df.describe())

x, y = df.iloc[:, 1:], df.iloc[:, 0]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 1)
clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)
clf.fit(x, y)

importances = clf.feature_importances_
print('importances:', importances)
labels = df.columns[1:]
indices = np.argsort(importances)[::-1]
print('indices:', indices)
for f in range(x_train.shape[1]):
    print("%2d) %-*s %f" % (f + 1, 30, labels[indices[f]], importances[indices[f]]))
